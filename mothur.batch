# Put this file in the working directory, run747, with the silva database and trainsets.
# Process paired-end reads, screen, cluster, and classify.
# Merge paired ends.
#make.contigs(file=clado.files, processors=7)
# Subsample 10% (default) of the reads from each sample. "Sampling 1348339 from 13483396."
sub.sample(fasta=clado.trim.contigs.fasta, group=clado.contigs.groups)
# Sanity check.
summary.seqs(fasta=current, count=current)
# Screen sequences with size limits that correspond to targeted regions (V3-V4) of 16S.
screen.seqs(fasta=current, group=current, maxambig=0, minlength=430, maxlength=490, processors=7)
# Sanity check.
summary.seqs(fasta=current, count=current)
# Boil contigs down to just the unique sequences.
unique.seqs()
# Sanity check.
summary.seqs(fasta=current, count=current)
# Count resulting unique sequences to generate a table of the number of each in each sample.
count.seqs(name=current, group=current)
# Count reads in each group (another sanity check).
count.groups(count=current)
# Curate / trim the Silva database to just V3-V4 regions to save on computing.
pcr.seqs(fasta=silva.bacteria/silva.bacteria.fasta, start=6334, end=25432, keepdots=F)
# Rename the curated /trimmed silva database.
system(mv silva.bacteria/silva.bacteria.pcr.fasta silva.bacteria/silva.v3v4.fasta)
# Align the sequences with new silva file.
align.seqs(fasta=clado.trim.contigs.subsample.good.unique.fasta, reference=silva.bacteria/silva.v3v4.fasta)
# Screen sequences based on alignment.
screen.seqs(fasta=current, count=current, start=54, end=18982, maxhomop=8)
# Sanity check.
summary.seqs(fasta=current, count=current)
# Remove consistent gaps in the alignment.
filter.seqs(fasta=current, vertical=T, trump=.)
# Sanity check.
summary.seqs(fasta=current, count=current)
# Get unique sequences only, again.
unique.seqs(fasta=current, count=current)
# Sanity check.
summary.seqs(fasta=current, count=current)
# Split the sequences by group and sort them by abundance, identifying sequences that are within 2 bases of each other. These are merged.
pre.cluster(fasta=current, count=current, diffs=4)
# Check for chimeras and remove.
chimera.uchime(fasta=current, count=current, dereplicate=t)
remove.seqs(fasta=current, accnos=current)
# Sanity check.
summary.seqs(fasta=current, count=current)
# Classify sequences. "It took 1792 secs to classify 273560 sequences."
classify.seqs(fasta=current, count=current, reference=trainset9_032012.pds.fasta, taxonomy=trainset9_032012.pds.tax, cutoff=80)
# Remove the sequences that were classified as non-bacteria.
remove.lineage(fasta=current, count=current, taxonomy=current, taxon=Chloroplast-Mitochondria-unknown-Archaea-Eukaryota)
summary.seqs(fasta=current, count=current)
# Cluster sequences into OTUs. "It took 47754 seconds to cluster" or ~13.25 hours.
cluster.split(fasta=current, count=current, taxonomy=current, splitmethod=classify, taxlevel=4, cutoff=0.15)
# Find out how many sequences are in each OTU from each group.
make.shared(list=current, count=current, label=0.03)
# Find out the taxonomy for each OTU.
classify.otu(list=current, count=current, taxonomy=current, label=0.03)
# Bin sequences in to phylotypes according to their taxonomic classification.
phylotype(taxonomy=current)
# Make a genus-level shared file.
make.shared(list=current, count=current, label=1)
# Run classify.otu() again but on the phylotypes.
classify.otu(list=current, count=current, taxonomy=current, label=1)
### Analysis
system(mv clado.trim.contigs.subsample.good.unique.good.filter.unique.precluster.pick.pick.an.unique_list.shared clado.an.shared)
system(mv clado.trim.contigs.subsample.good.unique.good.filter.unique.precluster.pick.pick.an.unique_list.0.03.cons.taxonomy clado.an.cons.taxonomy)
count.groups(shared=clado.an.shared)
sub.sample(shared=clado.an.shared, size=9261)
rarefaction.single(shared=clado.an.shared, calc=sobs, freq=100)
summary.single(shared=clado.an.shared, calc=nseqs-coverage-sobs-invsimpson, subsample=9261)
# Heatmaps
heatmap.bin(shared=clado.an.0.03.subsample.shared, scale=log2, numotu=50)
dist.shared(shared=clado.an.shared, calc=thetayc-jclass, subsample=9261)
heatmap.sim(phylip=clado.an.thetayc.0.03.lt.ave.dist)
heatmap.sim(phylip=clado.an.jclass.0.03.lt.ave.dist)
# Venn diagram of three samples from two times and two places
venn(shared=clado.an.0.03.subsample.shared, groups=C172N1-C172N2-C172S1-C172S2)
tree.shared(phylip=clado.an.thetayc.0.03.lt.ave.dist)
# Make and use site and time design files.
parsimony(tree=clado.an.thetayc.0.03.lt.ave.tre, group=clado.time.design,  groups=all)
#parsimony(tree=clado.an.thetayc.0.03.lt.ave.tre, group=clado.site.design,  groups=all)
pcoa(phylip=clado.an.thetayc.0.03.lt.ave.dist)
#nmds(phylip=clado.an.thetayc.0.03.lt.ave.dist)
nmds(phylip=clado.an.thetayc.0.03.lt.ave.dist, mindim=3, maxdim=3)
#amova(phylip=clado.an.thetayc.0.03.lt.ave.dist, design=clado.site.design)
amova(phylip=clado.an.thetayc.0.03.lt.ave.dist, design=clado.time.design)
#homova(phylip=clado.an.thetayc.0.03.lt.ave.dist, design=clado.site.design)
homova(phylip=clado.an.thetayc.0.03.lt.ave.dist, design=clado.time.design)
corr.axes(axes=clado.an.thetayc.0.03.lt.ave.nmds.axes, shared=clado.an.0.03.subsample.shared, method=spearman, numaxes=3)
# Make file with average water temps on sampling days. (Takes way too long.)
#get.communitytype(shared=clado.an.0.03.subsample.shared)
# Pop-level analysis
metastats(shared=clado.an.0.03.subsample.shared, design=clado.time.design)
#metastats(shared=clado.an.0.03.subsample.shared, design=clado.site.design)
classify.rf(shared=clado.an.0.03.subsample.shared, design=clado.time.design)
#classify.rf(shared=clado.an.0.03.subsample.shared, design=clado.site.design)

make.biom(shared=clado.an.shared, metadata=clado.metadata)

### Not refactored:
# Phylogeny-based analysis
#phylo.diversity(tree=clado.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.phylip.tre, count=clado.trim.contigs.good.unique.good.filter.unique.precluster.denovo.uchime.pick.pick.pick.count_table, rarefy=T)
#unifrac.unweighted(tree=clado.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.phylip.tre, count=clado.trim.contigs.good.unique.good.filter.unique.precluster.denovo.uchime.pick.pick.pick.count_table, distance=lt, processors=2, random=F, subsample=____)
#unifrac.weighted(tree=clado.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.phylip.tre, count=clado.trim.contigs.good.unique.good.filter.unique.precluster.denovo.uchime.pick.pick.pick.count_table, distance=lt, processors=2, random=F, subsample=____)
